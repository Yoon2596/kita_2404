{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMvRHT28fj1BeoXAciYt1uo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Task1_0806. 다음 사항을 준수하여 Fashion MNINS 데이터셋에 대하여 Sequential 방식으로 모델 생성 및 평가를 수행하세요.\n","- 입력 계층 및 첫 번째 Dense 계층 : 출력 512, activation='relu'\n","- 두 번째 Dense 계층 : 출력 256, activation='relu'\n","- 출력 계층 : 출력 10, activation='softmax'\n","- 모델 컴파일 : optimizer='adam', loss='categorical_crossentropy',         metrics=['accuracy']\n","- 모델 학습 : epochs=10, batch_size=64\n","<br>\n","layers.InputLayer(input_shape=(28*28,)),\n","<br>\n","기존이 MNIST 데이터셋과 같은 형식을 가지고 있지만, 손으로 쓴 숫자 대신에 10가지 범주의 패션 아이템(티셔츠, 바지, 신발)의 이미지로 구정"],"metadata":{"id":"K0CSupZxzxAF"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"PkAnwGAjzwNi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722990084213,"user_tz":-540,"elapsed":26021,"user":{"displayName":"Joe Ryu","userId":"01875545587582591965"}},"outputId":"be19b08f-51c4-4fc7-8c21-4ec33468e23a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.5981\n","Epoch 2/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3641\n","Epoch 3/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.3196\n","Epoch 4/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.2948\n","Epoch 5/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2681\n","Epoch 6/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.2661\n","Epoch 7/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2463\n","Epoch 8/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2392\n","Epoch 9/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2225\n","Epoch 10/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2117\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.3191\n","모델 정확도 : 0.8862000107765198\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# Fashion MNIST 데이터셋 로드\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","# 이미지 데이터 전처리\n","train_images = train_images.astype('float32') / 255\n","test_images = test_images.astype('float32') / 255\n","\n","# 레이블을 원-핫 인코딩\n","train_labels = to_categorical(train_labels, 10)\n","test_labels = to_categorical(test_labels, 10)\n","\n","# 모델 정의\n","model = models.Sequential()\n","\n","# 모델 구성\n","model.add(layers.InputLayer(input_shape=(28, 28)))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(512, activation='relu'))  # 첫 번째 완전 연결 레이어\n","model.add(layers.Dense(256, activation='relu'))  # 두 번째 연결 레이어\n","model.add(layers.Dense(10, activation='softmax'))  # 출력 레이어\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 모델 훈련\n","model.fit(train_images, train_labels, epochs=10, batch_size=64)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(f'모델 정확도 : {test_acc}')\n"]},{"cell_type":"markdown","source":["# 강사님 버전"],"metadata":{"id":"knq8eURoPfcU"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","train_images[0].shape\n","\n","image_data = train_images[0]\n","\n","plt.figure(figsize=(1, 1))\n","plt.imshow(image_data, cmap='gray')\n","plt.axis('off')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":114},"id":"x-5M7qrQNsXu","executionInfo":{"status":"ok","timestamp":1722990280636,"user_tz":-540,"elapsed":399,"user":{"displayName":"Joe Ryu","userId":"01875545587582591965"}},"outputId":"58274104-b985-4789-c643-3357a0e06a8b"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 100x100 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# Fashion MNIST 데이터셋 로드\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","# 이미지 데이터를 0과 1 사이의 값으로 정규화\n","train_images = train_images / 255\n","test_images = test_images / 255\n","\n","# 이미지 데이터를 1D 벡터로 변환 (28x28 이미지를 784 크기의 벡터로 평탄화)\n","train_images = train_images.reshape((-1, 28*28))\n","test_images = test_images.reshape((-1, 28*28))\n","\n","# 레이블을 원-핫 인코딩\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","# 첫번째 방법\n","# # 모델 정의\n","# model = models.Sequential()\n","\n","# # 모델 구성\n","# model.add(layers.InputLayer(input_shape=(28*28,)))\n","# model.add(layers.Dense(512, activation='relu'))  # 첫 번째 완전 연결 레이어\n","# model.add(layers.Dense(256, activation='relu'))  # 두 번째 연결 레이어\n","# model.add(layers.Dense(10, activation='softmax'))  # 출력 레이어\n","\n","# 두번째 방법\n","model = models.Sequential([\n","    layers.InputLayer(shape=(28*28,)),\n","    layers.Dense(512, activation='relu'),\n","    layers.Dense(256, activation='relu'),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 모델 훈련\n","model.fit(train_images, train_labels, epochs=10, batch_size=64)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(f'모델 정확도 : {test_acc}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jRNp8MtZOYHU","executionInfo":{"status":"ok","timestamp":1722991241527,"user_tz":-540,"elapsed":31081,"user":{"displayName":"Joe Ryu","userId":"01875545587582591965"}},"outputId":"f3255ae5-1dd7-4047-f347-822fffcff4b4"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.6101\n","Epoch 2/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3575\n","Epoch 3/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.3187\n","Epoch 4/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.2892\n","Epoch 5/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.2752\n","Epoch 6/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2553\n","Epoch 7/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2434\n","Epoch 8/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2284\n","Epoch 9/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2183\n","Epoch 10/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2112\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.3239\n","모델 정확도 : 0.8895000219345093\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# Fashion MNIST 데이터셋 로드\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","# 이미지 데이터를 0과 1 사이의 값으로 정규화\n","train_images = train_images / 255\n","test_images = test_images / 255\n","\n","# 레이블을 원-핫 인코딩\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","\n","# 이미지 차원 변경 (모델에 맞게 차원 추가)\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","\n","\n","\n","model = models.Sequential([\n","    # 컨볼루션 레이어 추가\n","    layers.InputLayer(shape=(28, 28, 1)),\n","    layers.Conv2D(32, (3, 3), activation='relu'),   # 32은 필터의 개수, (3, 3) 은 필터의 사이즈\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","\n","    # Dense 레이터 추가\n","    layers.Flatten(),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 모델 훈련\n","model.fit(train_images, train_labels, epochs=10, batch_size=64)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(f'모델 정확도 : {test_acc}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0RsKVlmSBJA","executionInfo":{"status":"ok","timestamp":1722991631402,"user_tz":-540,"elapsed":46029,"user":{"displayName":"Joe Ryu","userId":"01875545587582591965"}},"outputId":"1a55cc4c-5555-4401-bb07-a0e6f3eafdee"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7190 - loss: 0.7714\n","Epoch 2/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.3496\n","Epoch 3/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.2988\n","Epoch 4/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2640\n","Epoch 5/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2403\n","Epoch 6/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2180\n","Epoch 7/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.2001\n","Epoch 8/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9329 - loss: 0.1797\n","Epoch 9/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9382 - loss: 0.1656\n","Epoch 10/10\n","\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.1544\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2704\n","모델 정확도 : 0.9146000146865845\n"]}]}]}