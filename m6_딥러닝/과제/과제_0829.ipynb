{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOdY2nnK3pnEamb8Zxb2ZyN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Task1_0829. 가상 데이터 생성 (generate_data 함수) 후 모델링 및 평가하세요\n","- generate_data 함수는 1000개의 랜덤 시퀀스 데이터를 생성합니다.\n","  - vocab_size: 시퀀스에 사용할 어휘의 크기를 설정합니다. 여기서는 100개의 단어를 사용합니다.\n","  - data: 각 시퀀스는 seq_length=10으로 설정된 10개의 정수(단어 인덱스)로 구성됩니다.\n","  - labels: 각 시퀀스에 대해 0 또는 1의 이진 레이블을 무작위로 할당합니다.\n","\n","- LSTM 기반 분류 모델을 정의하고, 가상 데이터로 학습 및 검증을 수행합니다.\n","- 조기 종료를 통해 학습 중 성능이 더 이상 개선되지 않을 때 학습을 중단합니다.\n","최종적으로 테스트 데이터로 최고 성능의 모델을 평가합니다."],"metadata":{"id":"yYXE1SQ5Pyve"}},{"cell_type":"markdown","source":["#### nn.Embedding(vocag_size,embed_dim)\n","- 텍스트 데이터(LSTM 모델): 텍스트 데이터는 이산적인 정수로 표현되므로, 이 정수들을 고차원 벡터로 매핑하는 nn.Embedding 계층이 필요합니다. 이 임베딩 계층은 단어 간의 의미적 유사성을 학습하는 데 유용합니다.\n","\n","- 이미지 데이터(CNN 모델): 이미지 데이터는 이미 공간적 구조를 가진 연속적인 값(픽셀)으로 표현되므로, 임베딩 계층이 필요하지 않습니다. 대신, 합성곱 계층이 이미지의 패턴을 학습하는 데 사용됩니다.\n","\n","LSTM 모델의 경우 텍스트 데이터의 정수 인덱스를 벡터로 변환하기 위해 nn.Embedding이 필요하지만, CNN 모델에서는 이미지 데이터를 처리하는 데 이미 직접적인 합성곱 연산이 사용되므로 임베딩 계층이 필요하지 않습니다."],"metadata":{"id":"LhHT7wvGn1_U"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","\n","# 가상 데이터 생성 함수\n","def generate_data(num_samples=1000, seq_length=10):\n","    vocab_size = 100  # 어휘집 크기\n","    data = torch.randint(0, vocab_size, (num_samples, seq_length))\n","    labels = torch.randint(0, 2, (num_samples,))  # 0 또는 1의 레이블\n","    return data, labels\n","\n","data, labels = generate_data()"],"metadata":{"id":"RDY2H77TPyli","executionInfo":{"status":"ok","timestamp":1724976960065,"user_tz":-540,"elapsed":10004,"user":{"displayName":"Joe Ryu","userId":"01875545587582591965"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# 강사님 버전"],"metadata":{"id":"DeV2xy_vq3uh"}},{"cell_type":"code","source":["\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","\n","# 가상 데이터 생성 함수\n","def generate_data(num_samples=1000, seq_length=10):\n","    vocab_size = 100  # 어휘집 크기\n","    data = torch.randint(0, vocab_size, (num_samples, seq_length))\n","    labels = torch.randint(0, 2, (num_samples,))  # 0 또는 1의 레이블\n","    return data, labels\n","\n","data, labels = generate_data()\n","\n","# 텐서 데이터셋 및 데이터 로더 생성\n","dataset = TensorDataset(data, labels)\n","train_size = int(0.7 * len(dataset))\n","val_size = int(0.15 * len(dataset))\n","test_size = len(dataset) - (train_size + val_size)\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# LSTM 모델 클래스 정의\n","class LSTMModel(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, text):\n","        embedded = self.embedding(text)\n","        lstm_out, (hidden, _) = self.lstm(embedded)\n","        hidden = hidden[-1,:,:]\n","        return self.fc(hidden)\n","\n","model = LSTMModel(vocab_size=100, embed_dim=50, hidden_dim=100, output_dim=1)\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters())\n","\n","# 훈련 함수\n","def train(model, train_loader, optimizer, criterion):\n","    model.train()\n","    total_loss = 0\n","    for data, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(data).squeeze(1)\n","        loss = criterion(outputs, labels.float())\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(train_loader)\n","\n","# 평가 함수\n","def evaluate(model, data_loader, criterion):\n","    model.eval()\n","    total_loss = 0\n","    total_accuracy = 0\n","    with torch.no_grad():\n","        for data, labels in data_loader:\n","            outputs = model(data).squeeze(1)\n","            loss = criterion(outputs, labels.float())\n","            total_loss += loss.item()\n","            predictions = torch.round(torch.sigmoid(outputs))\n","            correct_predictions = (predictions == labels.unsqueeze(1)).float()\n","            total_accuracy += correct_predictions.sum().item()\n","    return total_loss / len(data_loader), total_accuracy / len(data_loader.dataset)\n","\n","# 조기 종료 로직을 포함한 훈련 및 검증 과정\n","best_val_loss = float('inf') # float('inf')는 파이썬에서 양의 무한대를 나타내는 방식\n","patience = 3\n","trials = 0\n","\n","for epoch in range(20):\n","    train_loss = train(model, train_loader, optimizer, criterion)\n","    val_loss, val_accuracy = evaluate(model, val_loader, criterion)\n","    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        trials = 0\n","        torch.save(model.state_dict(), 'best_model.pth')\n","    else:\n","        trials += 1\n","        if trials >= patience:\n","            print(\"조기 종료 발생\")\n","            break\n","\n","# 테스트 데이터로 최고 모델 평가\n","model.load_state_dict(torch.load('best_model.pth'))\n","test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n","print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"],"metadata":{"id":"oCNPGE8Oou12"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["nn.BCEWithLogitsLoss는 PyTorch에서 이진 분류(Binary Classification) 작업을 수행할 때 주로 사용하는 손실 함수입니다. 이 함수는 이진 교차 엔트로피 손실(Binary Cross Entropy Loss)와 시그모이드(Sigmoid) 함수를 결합한 형태로 제공됩니다."],"metadata":{"id":"U_MdNTXbrPKM"}}]}