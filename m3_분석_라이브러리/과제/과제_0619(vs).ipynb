{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1_0619. 다음 사항을 수행하세요.\n",
    "- 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "- 모든 'p' 태그 찾기\n",
    "- 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "- 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "- 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "- 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "- 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "- 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "- 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "- 특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = '<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   Title\n",
      "  </h1>\n",
      "  <p class=\"content\">\n",
      "   First paragraph.\n",
      "  </p>\n",
      "  <p class=\"content\">\n",
      "   Second paragraph.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">First paragraph.</p> \n",
      "\n",
      "[<p class=\"content\">First paragraph.</p>, <p class=\"content\">Second paragraph.</p>] \n",
      "\n",
      "<p class=\"content\">First paragraph.</p> \n",
      "\n",
      "[<p class=\"content\">First paragraph.</p>, <p class=\"content\">Second paragraph.</p>] \n",
      "\n",
      "body\n",
      "body\n",
      "\n",
      "body \n",
      "\n",
      "<p class=\"content\">Second paragraph.</p> \n",
      "\n",
      "<h1>Title</h1> \n",
      "\n",
      "<p class=\"content\">Second paragraph.</p>\n",
      "Second paragraph. \n",
      "\n",
      "<h1>Title</h1>\n",
      "Title\n"
     ]
    }
   ],
   "source": [
    "#1. 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "first_p = soup.find('p')\n",
    "print(first_p, '\\n')\n",
    "\n",
    "#2. 모든 'p' 태그 찾기\n",
    "all_p = soup.find_all('p')\n",
    "print(all_p, '\\n')\n",
    "\n",
    "#3. 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "first_content = soup.find(class_='content')\n",
    "print(first_content, '\\n')\n",
    "\n",
    "#4. 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "# all_content = soup.find_all(class_='content')\n",
    "all_content = soup.select('.content')\n",
    "print(all_content, '\\n')\n",
    "\n",
    "#5. 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "p_tag = soup.find_all('p')\n",
    "for p in p_tag:\n",
    "    print(p.parent.name)\n",
    "print()\n",
    "#6. 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "p_tag = soup.find('p')\n",
    "p_parent = p_tag.parent.name\n",
    "print(p_parent, '\\n')\n",
    "\n",
    "#7. 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "new_p = soup.find('p')\n",
    "# print(new_p)\n",
    "print(new_p.find_next_sibling(), '\\n')\n",
    "\n",
    "#8. 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "print(new_p.find_previous_sibling(), '\\n')\n",
    "\n",
    "#9. 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "p_tag2 = soup.find('p', class_='content')\n",
    "p2 = p_tag2.find_next_sibling()\n",
    "print(p2)\n",
    "print(p2.get_text(), '\\n')\n",
    "\n",
    "#10.특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기 \n",
    "p_tag2 = soup.find('p', class_='content')\n",
    "p2 = p_tag2.find_previous_sibling()\n",
    "print(p2)\n",
    "print(p2.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2_0619. ID를 이용해서 '네이버 뉴스' 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'http://news.naver.com'\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네이버 뉴스\n",
      "네이버 뉴스\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "naver_news = soup.select_one('#browserTitleArea')\n",
    "print(naver_news.text)\n",
    "\n",
    "naver_news2 = soup.find(id='browserTitleArea')\n",
    "print(naver_news2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3_0619. soup.find_all(class_='Nitem_link_menu') 대신에 select를 이용하여 동일한 결과를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"Nitem_link_menu\">언론사별</span>\n",
      "<span class=\"Nitem_link_menu\">정치</span>\n",
      "<span class=\"Nitem_link_menu\">경제</span>\n",
      "<span class=\"Nitem_link_menu\">사회</span>\n",
      "<span class=\"Nitem_link_menu\">생활/문화</span>\n",
      "<span class=\"Nitem_link_menu\">IT/과학</span>\n",
      "<span class=\"Nitem_link_menu\">세계</span>\n",
      "<span class=\"Nitem_link_menu\">랭킹</span>\n",
      "<span class=\"Nitem_link_menu\">신문보기</span>\n",
      "<span class=\"Nitem_link_menu\">오피니언</span>\n",
      "<span class=\"Nitem_link_menu\">TV</span>\n",
      "<span class=\"Nitem_link_menu\">팩트체크</span>\n",
      "<span class=\"Nitem_link_menu\">알고리즘 안내</span>\n",
      "<span class=\"Nitem_link_menu\">정정보도 모음</span>\n"
     ]
    }
   ],
   "source": [
    "q = soup.find_all(class_='Nitem_link_menu')\n",
    "for i in q:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"Nitem_link_menu\">언론사별</span>,\n",
       " <span class=\"Nitem_link_menu\">정치</span>,\n",
       " <span class=\"Nitem_link_menu\">경제</span>,\n",
       " <span class=\"Nitem_link_menu\">사회</span>,\n",
       " <span class=\"Nitem_link_menu\">생활/문화</span>,\n",
       " <span class=\"Nitem_link_menu\">IT/과학</span>,\n",
       " <span class=\"Nitem_link_menu\">세계</span>,\n",
       " <span class=\"Nitem_link_menu\">랭킹</span>,\n",
       " <span class=\"Nitem_link_menu\">신문보기</span>,\n",
       " <span class=\"Nitem_link_menu\">오피니언</span>,\n",
       " <span class=\"Nitem_link_menu\">TV</span>,\n",
       " <span class=\"Nitem_link_menu\">팩트체크</span>,\n",
       " <span class=\"Nitem_link_menu\">알고리즘 안내</span>,\n",
       " <span class=\"Nitem_link_menu\">정정보도 모음</span>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = soup.select('.Nitem_link_menu')\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task4_0619. select_one을 이용해서 'https://news.naver.com'에서 \"뉴스\"를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"Nicon_service\">뉴스</span>\n",
      "뉴스\n"
     ]
    }
   ],
   "source": [
    "news = soup.select_one('.Nicon_service')\n",
    "print(news)\n",
    "print(news.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task5_0619.'https://news.naver.com'에서 아래 예시와 같이 뉴스 기사 제목을 모두 출력하세요. \n",
    "예시: 1: [속보] '훈련병 사망' 얼차려 지시 중대장·부중대장 피의자 신분 첫 소환조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:[속보]尹 \"'인구 국가비상사태' 선언… 양육·주거 등 지원 확대\"\n",
      "2:[속보]尹대통령, '인구 국가비상사태' 선언…\"범국가적 총력 대응, 아빠 출산휴가 20일로 확대\"\n",
      "3:[속보]尹대통령, ‘인구 국가비상사태’ 선언…“범국가적 총력 대응”\n",
      "4:[속보]윤, '인구 국가비상사태' 선언…\"육휴 첫 3개월 급여 250만원으로\"\n",
      "5:[속보]尹 \"인구전략기획부 명칭 확정, 오늘부로 인구 국가비상사태\"\n",
      "6:[속보]尹, ‘인구 국가비상사태’ 선언…“범국가적 총력 대응”\n",
      "7:[속보]尹, '인구 국가비상사태' 선언…\"범국가적 총력 대응\"\n",
      "8:[속보] 尹 \"육아휴직 급여, 첫 3개월 월 250만원으로 대폭 인상\"\n",
      "9:[속보]윤 대통령, '인구 국가비상사태' 선언…\"범국가적 총력 대응\"\n",
      "10:[속보]연 1회 '2주 단위' 육아휴직 도입…혼인신고만 해도 특별세액공제\n",
      "11:[속보]윤, '인구 국가비상사태' 선언…\"범국가적 총력 대응\"\n",
      "12:[속보]尹 대통령, “저출생 극복할 때까지 범국가적 총력대응”\n",
      "13:[속보]윤 대통령, ‘인구 국가비상사태’ 선언…“범국가적 총력 대응”\n",
      "14:[속보]육아휴직 급여 인상…초반 3개월 '최대 250만원'\n",
      "15:[속보]尹대통령, '인구 국가비상사태' 선언…\"범국가적 총력 대응\"\n",
      "16:[속보]尹 \"출산가구에 청약기회·특별공급 확대…신혼부부 저리대출\"\n",
      "17:[속보]윤 대통령 “인구 국가 비상사태 선언…저출산 총력 대응 체계 가동”\n",
      "18:[속보]尹 '인구 국가비상사태' 선언…\"저출생 극복 범국가적 총력 대응\"\n",
      "19:[속보]尹 \"오늘부로 '인구 국가비상사태' 선언…범국가적 총력대응체계 가동\"\n",
      "20:[속보]'조국 아들 인턴 허위 발언' 최강욱 2심도 벌금 80만원\n"
     ]
    }
   ],
   "source": [
    "articles = soup.find_all(class_='cn_title')\n",
    "article=[]\n",
    "for i in articles:\n",
    "    a = i.text\n",
    "    article.append(a)\n",
    "\n",
    "article\n",
    "\n",
    "title=[]\n",
    "for i in article:\n",
    "    if i not in title:\n",
    "        title.append(i)\n",
    "    else:\n",
    "        pass\n",
    "title\n",
    "\n",
    "for idx, i in enumerate(title):\n",
    "    print(f'{idx+1}:[속보]{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스스탠드 링크를 찾을 수 없습니다\n"
     ]
    }
   ],
   "source": [
    "# 동적 콘텐츠 로딩 : selenium 사용\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "# options.add_argument('--start-maximized')\n",
    "options.add_experimental_option('detach', True)\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# 네이버 페이지 열기\n",
    "url = 'http://www.naver.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# 페이지 로딩 대기\n",
    "time.sleep(2)   # 2초 대기 (필요에 따라 조정)\n",
    "\n",
    "# 뉴스 스탠드 링크 찾기\n",
    "try:\n",
    "    newsarticle_link = driver.find_elements(By.CSS_SELECTOR, \"#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div:nth-child(2)\")\n",
    "    print(newsarticle_link.text)\n",
    "except:\n",
    "    print(\"뉴스스탠드 링크를 찾을 수 없습니다\")\\\n",
    "#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div:nth-child(2) > div > div > div\n",
    "# document.querySelector(\"#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div:nth-child(2) > div > div > div > a\")\n",
    "#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk.ContentHeaderSubView-module__type_enter___fHZXq\n",
    "#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div:nth-child(2)\n",
    "# 브라우저 닫기    \n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
