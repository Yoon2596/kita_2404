{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1_0619. 다음 사항을 수행하세요.\n",
    "- 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "- 모든 'p' 태그 찾기\n",
    "- 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "- 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "- 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "- 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "- 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "- 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "- 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "- 특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = '<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   Title\n",
      "  </h1>\n",
      "  <p class=\"content\">\n",
      "   First paragraph.\n",
      "  </p>\n",
      "  <p class=\"content\">\n",
      "   Second paragraph.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">First paragraph.</p> \n",
      "\n",
      "[<p class=\"content\">First paragraph.</p>, <p class=\"content\">Second paragraph.</p>] \n",
      "\n",
      "<p class=\"content\">First paragraph.</p> \n",
      "\n",
      "[<p class=\"content\">First paragraph.</p>, <p class=\"content\">Second paragraph.</p>] \n",
      "\n",
      "<p class=\"content\">First paragraph.</p>\n",
      "[<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]\n",
      "body\n",
      "html\n",
      "[document]\n",
      "\n",
      "body\n",
      "<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body> \n",
      "\n",
      "<p class=\"content\">Second paragraph.</p> \n",
      "\n",
      "<h1>Title</h1> \n",
      "\n",
      "<p class=\"content\">Second paragraph.</p>\n",
      "Second paragraph. \n",
      "\n",
      "<p class=\"content\">Second paragraph.</p>\n",
      "Second paragraph.\n"
     ]
    }
   ],
   "source": [
    "#1. 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "first_p = soup.find('p')\n",
    "print(first_p, '\\n')\n",
    "\n",
    "#2. 모든 'p' 태그 찾기\n",
    "all_p = soup.find_all('p')\n",
    "print(all_p, '\\n')\n",
    "\n",
    "#3. 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "first_content = soup.find(class_='content')\n",
    "print(first_content, '\\n')\n",
    "\n",
    "#4. 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "# all_content = soup.find_all(class_='content')\n",
    "all_content = soup.select('p.content')\n",
    "print(all_content, '\\n')\n",
    "\n",
    "#5. 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "# [document] -> <html> -> <body> -> <p> : 최상위 요소 document에서 시작하여 p 태그까지의 모든 부모 요소를 출력\n",
    "p_tag = soup.find('p', class_='content')\n",
    "print(p_tag)\n",
    "parents = p_tag.find_parents()\n",
    "print(parents)\n",
    "for p in parents:\n",
    "    print(p.name)\n",
    "print()\n",
    "#6. 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "p_tag = soup.find('p')\n",
    "p_parent = p_tag.parent.name\n",
    "p_parent1 = p_tag.find_parent()\n",
    "print(p_parent)\n",
    "print(p_parent1, '\\n')\n",
    "\n",
    "#7. 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "new_p = soup.find('p')\n",
    "# print(new_p)\n",
    "print(new_p.find_next_sibling(), '\\n')\n",
    "\n",
    "#8. 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "print(new_p.find_previous_sibling(), '\\n')\n",
    "\n",
    "#9. 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "p_tag2 = soup.find('p', class_='content')\n",
    "p2 = p_tag2.find_next_sibling()\n",
    "print(p2)\n",
    "print(p2.get_text(), '\\n')\n",
    "\n",
    "#10.특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기 \n",
    "p_tag2 = soup.find('p', class_='content')\n",
    "p2 = p_tag2.find_next()\n",
    "print(p2)\n",
    "print(p2.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>,\n",
       " <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>,\n",
       " <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tag = soup.find('p')\n",
    "# p_parent = p_tag.parent.name\n",
    "p_parent1 = p_tag.find_parents()\n",
    "# print(p_parent, '\\n')\n",
    "p_parent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2_0619. ID를 이용해서 '네이버 뉴스' 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'http://news.naver.com'\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네이버 뉴스\n",
      "네이버 뉴스\n",
      "네이버 뉴스\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "naver_news = soup.select_one('#browserTitleArea')\n",
    "print(naver_news.text)\n",
    "\n",
    "naver_news2 = soup.find('title', id='browserTitleArea')\n",
    "print(naver_news2.text)\n",
    "\n",
    "naver_news3 = soup.select_one('title#browserTitleArea')\n",
    "print(naver_news3.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3_0619. soup.find_all(class_='Nitem_link_menu') 대신에 select를 이용하여 동일한 결과를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 언론사별\n",
      "2: 정치\n",
      "3: 경제\n",
      "4: 사회\n",
      "5: 생활/문화\n",
      "6: IT/과학\n",
      "7: 세계\n",
      "8: 랭킹\n",
      "9: 신문보기\n",
      "10: 오피니언\n",
      "11: TV\n",
      "12: 팩트체크\n",
      "13: 알고리즘 안내\n",
      "14: 정정보도 모음\n"
     ]
    }
   ],
   "source": [
    "q = soup.find_all(class_='Nitem_link_menu')\n",
    "# for i in q:\n",
    "#     print(i)\n",
    "for idx, cat in enumerate(q):\n",
    "    print(f'{idx+1}: {cat.get_text().strip()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 언론사별\n",
      "2: 정치\n",
      "3: 경제\n",
      "4: 사회\n",
      "5: 생활/문화\n",
      "6: IT/과학\n",
      "7: 세계\n",
      "8: 랭킹\n",
      "9: 신문보기\n",
      "10: 오피니언\n",
      "11: TV\n",
      "12: 팩트체크\n",
      "13: 알고리즘 안내\n",
      "14: 정정보도 모음\n"
     ]
    }
   ],
   "source": [
    "ans = soup.select('.Nitem_link_menu')\n",
    "for idx, cat in enumerate(ans):\n",
    "    print(f'{idx+1}: {cat.get_text().strip()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task4_0619. select_one을 이용해서 'https://news.naver.com'에서 \"뉴스\"를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"Nicon_service\">뉴스</span>\n",
      "뉴스\n"
     ]
    }
   ],
   "source": [
    "news = soup.select_one('.Nicon_service')\n",
    "print(news)\n",
    "print(news.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"Nicon_service\">뉴스</span>\n",
      "뉴스\n"
     ]
    }
   ],
   "source": [
    "item_element = soup.select_one('span.Nicon_service')\n",
    "print(item_element)\n",
    "print(item_element.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task5_0619.'https://news.naver.com'에서 아래 예시와 같이 뉴스 기사 제목을 모두 출력하세요. \n",
    "예시: 1: [속보] '훈련병 사망' 얼차려 지시 중대장·부중대장 피의자 신분 첫 소환조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:[속보]한동훈 측 \"23일 오후 2시 국회에서 출마선언\"\n",
      "2:[속보]코스피 장중 2800선 돌파…2년 5개월 만\n",
      "3:[속보]한 총리 \"저출생·고령화 심화…외국인력 합리적 관리방안 마련\"\n",
      "4:[속보]코스피, 장중 2800선 돌파…2년 5개월만\n",
      "5:[속보]코스피, 2년5개월 만에 2800포인트 돌파…장 초반 강보합 \n",
      "6:[속보]코스피 2802.10, 원·달러 환율 1382.5개장\n",
      "7:[속보]코스피, 2800선 돌파…2년 5개월만\n"
     ]
    }
   ],
   "source": [
    "articles = soup.find_all(class_='cn_title')\n",
    "article=[]\n",
    "for i in articles:\n",
    "    a = i.text\n",
    "    article.append(a)\n",
    "\n",
    "article\n",
    "\n",
    "title=[]\n",
    "for i in article:\n",
    "    if i not in title:\n",
    "        title.append(i)\n",
    "    else:\n",
    "        pass\n",
    "title\n",
    "\n",
    "for idx, i in enumerate(title):\n",
    "    print(f'{idx+1}:[속보]{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스스탠드 링크를 찾을 수 없습니다\n"
     ]
    }
   ],
   "source": [
    "# 동적 콘텐츠 로딩 : selenium 사용\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "# options.add_argument('--start-maximized')\n",
    "options.add_experimental_option('detach', True)\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# 네이버 페이지 열기\n",
    "url = 'http://www.naver.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# 페이지 로딩 대기\n",
    "time.sleep(2)   # 2초 대기 (필요에 따라 조정)\n",
    "\n",
    "# 뉴스 스탠드 링크 찾기\n",
    "try:\n",
    "    newsarticle_link = driver.find_elements(By.CSS_SELECTOR, \"#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div:nth-child(2) > div > div > div > a\")\n",
    "    print(newsarticle_link.text)\n",
    "except:\n",
    "    print(\"뉴스스탠드 링크를 찾을 수 없습니다\")\\\n",
    "#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div:nth-child(2) > div > div > div\n",
    "# document.querySelector(\"#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div:nth-child(2) > div > div > div > a\")\n",
    "#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk.ContentHeaderSubView-module__type_enter___fHZXq\n",
    "#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div:nth-child(2)\n",
    "#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div\n",
    "# document.querySelector(\"#newsstand > div.ContentHeaderSubView-module__content_header_sub___Yszwk > div.ContentHeaderSubView-module__sub_news___DECMU > div:nth-child(2) > div > div > div > a\")\n",
    "# 브라우저 닫기    \n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:[속보]백종원·김어준·임영웅의 '굴욕'…'이 여자'한테 다 밀렸다…한국인 최애 유튜버는 누구?\n",
      "2:[속보]“귀엽지만 음식에 털 날려서…” 반려동물 식당 출입에 곳곳 갈등\n",
      "3:[속보]끝모를 쌀값 하락…“재고 15만t 신속 격리를”\n",
      "4:[속보]목동 아파트 화재 12시간 만에 진압…긴박했던 순간들\n",
      "5:[속보]푸틴, 또 김정은에게 ‘러시아판 롤스로이스’ 아우루스 선물\n",
      "6:[속보]징역 9년 6개월 이화영 판결문 속 이재명\n",
      "7:[속보]납품 전선 이상 無… 韓방산, 2분기 호실적 기대\n",
      "8:[속보]현빈이 입은 '이 옷' 해외서도 난리…주가 58% 뛰었는데 \"더 뛴다\"\n",
      "9:[속보]올해 장마 시작...제주 밤새 장맛비 내려\n",
      "10:[속보]서울 35도 ‘찜통더위’…제주 거센 장맛비\n",
      "11:[속보][단독] 영화숙·재생원 악몽, 국제사회에 첫 증언\n",
      "12:[속보]어제 ‘인구국가비상사태’ 보셨나요…‘진짜 비상사태’ 3가지 빠졌던데\n",
      "13:[속보]“자식 돈에 어디 숟가락”…박세리 논란에 소환된 손웅정\n",
      "14:[속보]이재명·한동훈 ‘단두대 매치’ 성사되나\n",
      "15:[속보]박세리 부친 입 열었다 \"아빠니까 나설 수 있다는 생각\"\n",
      "16:[속보]‘미투’ 서지현 검사 근황 보니…“정치권, ‘이대남’ 표 위해 ‘女 지우기’ 급급”\n",
      "17:[속보][이사람] 영업이익 18조원 달성한 정의선 회장…국내 그룹 총수 중 '최고'\n",
      "18:[속보]“비둘기, 멧돼지, 다람쥐 여러분…피임하세요” 과학자들 피임약 뿌려 개체수 조절 시험중\n",
      "19:[속보]내년 추석은 7일 쉰다…주5일 직장인 휴일 '119일'\n",
      "20:[속보]'김건희 논문 검증' 학생들 몰표‥'숙대'의 선택은\n",
      "21:[속보]“시청률 0%, 터질게 터졌다” 넷플릭스발 초유의 사태 ‘발칵’\n",
      "22:[속보]하늘에서 내려오는 ‘공짜’ 다이어트 보조제… 지금 실컷 누리자\n",
      "23:[속보]\"한쪽 침략당하면 상호지원\"…랍스터 먹고, 한밤 배웅까지\n",
      "24:[속보]내년 추석 연휴는 1주일…개천절부터 한글날까지 쉰다\n",
      "25:[속보]백종원·곽튜브 제쳤다… 한국인이 좋아하는 유튜버 1위는?\n",
      "26:[속보]\"자식 돈에 어디 숟가락 얹나\"…박세리 논란에 손흥민父 재조명\n",
      "27:[속보]바지 벗고 길에 쪼그려 앉은 아이…제주 발칵 뒤집은 영상 [잇슈 키워드]\n",
      "28:[속보]\"이게 무슨 추태냐\"...'대구 공무원 치킨집 갑질' 탄식에 홍준표 한마디\n",
      "29:[속보]오물 풍선 소동, 끝난 게 아니다\n",
      "30:[속보]제로라니까 제로인 줄 알았어? '제로슈거'의 거짓말 [추적+]\n",
      "31:[속보]‘형만 믿어’…한반도 유사시 러시아 개입 길 열렸다 [뉴스+]\n",
      "32:[속보][단독] 놀이동산서 불법 촬영한 10대 학생 '덜미'\n",
      "33:[속보]이스라엘군 대변인 \"하마스 궤멸, 사실상 불가능\"…공개 발언서 지도부 저격\n",
      "34:[속보]북러, 포괄적 동반자 협정 체결 \"침략 당하면 상호지원\"\n",
      "35:[속보]길거리서 용변 본 아이, 엄마는 나 몰라라.. \"몰상식 행위  처벌해야\"\n",
      "36:[속보]권도형 구금 몬테네그로 총리, 알고 보니 ‘테라 초기 투자자’\n",
      "37:[속보]내년 '빨간 날'은 언제?…\"추석 대박\" 2025년 월력요항 발표\n",
      "38:[속보]김호중 음주운전 혐의 제외에…\"우리도 도망가자\" 공분\n",
      "39:[속보]비대면 대출 해준다더니…돌아온 건 계좌 정지\n",
      "40:[속보]'갤럭시 A35' 국내 출시…\"엔터테인먼트 시청에 최적\"\n",
      "41:[속보]“한달에 3천만원 저축, 연봉 5~6억”…악착같이 모은다는 무명개그맨의 정체\n",
      "42:[속보]“푸틴 태우고 운전” 김정은 포착…선물받은 ‘아우루스’ 직접 몰았다\n",
      "43:[속보]Summit of two loners: Kim breaks seclusion with Putin by his side\n",
      "44:[속보]지방선거까지 尹-韓 충돌 없다? '출마 임박' 韓 앞 '고차방정식'\n",
      "45:[속보]\"버티다, 버티다 못해 가입했다\"…신규 요금제 이용 유도하는 배민[배달앱의배신]\n",
      "46:[속보]푸틴, 21시간 방북 종료…김정은, 비행기 뜰 때까지 손 흔들어\n",
      "47:[속보]대통령실 '길목' 첫 조사…관심 모드는 김건희 여사 조사\n",
      "48:[속보]\"몸이 갑자기 거인처럼 커진다\" 감각이 왜곡된다는 女, 무슨 증후군?\n",
      "49:[속보]\"李 민주당의 아버지\" 찬사에…진중권 \"아바이 수령, 이재명 주석 만세!\"\n",
      "50:[속보]\"자식 돈은 자식 돈, 어디 숟가락을 얹나\"…박세리 논란에 손흥민 父 손웅정 발언 재조명\n",
      "51:[속보]\"재명2년\"…이재명 저격한 진중권, 무슨 뜻인가 봤더니\n",
      "52:[속보]영국 명소 스톤헨지에 환경단체 주황 물감 스프레이 분사\n",
      "53:[속보][인사이드 스토리]반전 거듭하는 애플…아이폰 슈퍼사이클 맞을까\n",
      "54:[속보]정신질환으로 우발적 살인? '심신미약'이면 여성 살해해도 되나\n",
      "55:[속보]종로 포차거리에서 흉기난동, 휴무 경찰이 제압\n",
      "56:[속보]은행 슈퍼앱, 디지털 헬스케어 품는다\n",
      "57:[속보]\"TV수신료 고지서 7월10일 도착한다\"\n",
      "58:[속보]\"자식 돈은 자식 돈, 어디 숟가락을 얹나\"…박세리 논란에 손웅정 발언 재조명\n",
      "59:[속보]에코+페미, 우리 지금 만나\n",
      "60:[속보]\"역대 가장 더운 6월\"..정읍 37.5도까지 치솟아\n",
      "61:[속보]한국인이 가장 좋아하는 유튜버 1위는?\n",
      "62:[속보]속속 드러난 부실 대응... 지차체 공무원 10명 추가 기소\n",
      "63:[속보]미분양 빠지고 고가에 팔리고… 바닷가만 꿈틀\n",
      "64:[속보]BBQ, '4000원 할인 쿠폰' 프로모션...민심 잡기 나선다\n",
      "65:[속보]Putin, Kim sign strategic partnership as North backs Russia's war in Ukraine\n",
      "66:[속보][도초도 수국축제] 지금 만나러 갑니다 1004만 송이 수국\n",
      "67:[속보]양육비 안 준 부모 164명, 출국금지·명단공개 등 제재\n",
      "68:[속보]AI가 광고를 만든다? \"중요한 건 인간의 판단력\"\n",
      "69:[속보]'채 해병 사건 회수' 시작점에 윤석열... 새 통화 기록 나왔다\n",
      "70:[속보][인터뷰] “한국 넘버원 역직구 플랫폼 꿈꾸죠”…딜리버드코리아 직원들의 자신감\n",
      "71:[속보]민주당내 '이재명 아버지' 발언에 진중권 \"연호도 붙여줘라\"\n",
      "72:[속보]석유공사 사장 \"말하면 알만한 글로벌 기업과 추가 검증 마쳤다\"\n",
      "73:[속보]尹 대통령 \"인구 국가비상사태\"…저출생 대책 드라이브 시동\n",
      "74:[속보]2025년 직장인 쉬는 날 119일…3일 이상 연휴 6번\n",
      "75:[속보]방문 요양보호사들 ‘임금 올려라’ 국가에 소송 제기\n",
      "76:[속보]\"음주운전하면 무조건 튀어라\"…'음주 혐의' 빠진 김호중에 뿔난 여론\n",
      "77:[속보][아워홈 남매의난 시즌2] 구미현 신임 회장, 아워홈 경영권 매각 공식화했지만...매각까지 '산 넘어 산'\n",
      "78:[속보]푸틴, 24년만의 방북…21시간 머물고 김정은 배웅 속 평양 떠나\n",
      "79:[속보]실질 지원 기대감 “해봐야”…익명 출산 딜레마 “해봤자”\n",
      "80:[속보]정용진 신세계 '신상필벌' 인사에 직원들 ‘긴장’\n",
      "81:[속보]3억 로또 줍줍…이번엔 성남에 20만명 몰렸다\n",
      "82:[속보][단독]‘몰카 안경’ 쓰고 유치장-판사 몰래 찍은 30대 여성 구속기소\n"
     ]
    }
   ],
   "source": [
    "titles = soup.select('.cjs_t')\n",
    "for idx, i in enumerate(titles):\n",
    "    print(f'{idx+1}:[속보]{i.get_text().strip()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
